import httpx
from typing import List, Optional, Dict, Any
import json

from src.llm.base import BaseLLMProvider, Message, LLMResponse, LLMProviderError


class OpenRouterProvider(BaseLLMProvider):
    """
    –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è OpenRouter (–¥–æ—Å—Ç—É–ø –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º LLM —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—ã–π API).

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏:
    - openai/gpt-oss-20b:free
    - anthropic/claude-3-opus
    - google/gemini-pro
    - meta-llama/llama-3-70b
    - –∏ –º–Ω–æ–≥–∏–µ –¥—Ä—É–≥–∏–µ
    """

    def __init__(
            self,
            model: str = "openai/gpt-oss-20b:free",
            temperature: float = 0.4,
            max_tokens: int = 2000,
            api_key: Optional[str] = None,
            base_url: str = "https://openrouter.ai/api/v1",
            timeout: int = 120,
            enable_reasoning: bool = False,
            **kwargs
    ):
        """
        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ OpenRouter
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            api_key: API –∫–ª—é—á OpenRouter (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
            base_url: URL OpenRouter API
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            enable_reasoning: –í–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º reasoning (–¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π)
        """
        super().__init__(model, temperature, max_tokens, **kwargs)

        if not api_key:
            raise LLMProviderError(
                "OpenRouter API key is required. "
                "Get it at: https://openrouter.ai/keys"
            )

        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.enable_reasoning = enable_reasoning

        # –°–æ–∑–¥–∞—ë–º HTTP –∫–ª–∏–µ–Ω—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
        self.client = httpx.AsyncClient(
            timeout=timeout,
            headers={
                "Authorization": f"Bearer {api_key}",
                "HTTP-Referer": "https://github.com/your-project",  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
                "X-Title": "Your App Name",  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            }
        )

    async def generate(
            self,
            messages: List[Message],
            system_prompt: Optional[str] = None,
            preserve_reasoning: bool = False
    ) -> LLMResponse:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ OpenRouter API.

        Args:
            messages: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            preserve_reasoning: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å reasoning_details –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            LLMResponse —Å –æ—Ç–≤–µ—Ç–æ–º –∏ reasoning_details (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        api_messages = []

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        if system_prompt:
            api_messages.append({
                "role": "system",
                "content": system_prompt
            })

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        for msg in messages:
            message_dict = msg.to_dict()

            # –ï—Å–ª–∏ —ç—Ç–æ Message –æ–±—ä–µ–∫—Ç —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
            if hasattr(msg, 'reasoning_details') and preserve_reasoning:
                message_dict['reasoning_details'] = msg.reasoning_details

            api_messages.append(message_dict)

        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
        payload = {
            "model": self.model,
            "messages": api_messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
        }

        # –î–æ–±–∞–≤–ª—è–µ–º reasoning –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if self.enable_reasoning:
            payload["extra_body"] = {
                "reasoning": {"enabled": True}
            }

        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            response = await self.client.post(
                f"{self.base_url}/chat/completions",
                json=payload
            )
            response.raise_for_status()

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            data = response.json()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            if not data.get("choices") or len(data["choices"]) == 0:
                raise LLMProviderError("Empty response from OpenRouter")

            message = data["choices"][0].get("message", {})
            content = message.get("content", "")

            if not content:
                raise LLMProviderError("Empty content in response")

            # –°–æ–∑–¥–∞—ë–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            llm_response = LLMResponse(
                content=content,
                raw_response=data
            )

            # –î–æ–±–∞–≤–ª—è–µ–º reasoning_details –µ—Å–ª–∏ –µ—Å—Ç—å
            if "reasoning_details" in message:
                llm_response.reasoning_details = message["reasoning_details"]

            return llm_response

        except httpx.ConnectError:
            raise LLMProviderError(
                "Cannot connect to OpenRouter API. "
                "Check your internet connection."
            )
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 401:
                raise LLMProviderError(
                    "Invalid API key. Get one at: https://openrouter.ai/keys"
                )
            elif e.response.status_code == 404:
                raise LLMProviderError(
                    f"Model '{self.model}' not found. "
                    f"Check available models at: https://openrouter.ai/models"
                )
            elif e.response.status_code == 429:
                raise LLMProviderError(
                    "Rate limit exceeded. Wait a moment and try again."
                )
            else:
                error_detail = e.response.text
                raise LLMProviderError(f"OpenRouter HTTP error: {e.response.status_code} - {error_detail}")
        except Exception as e:
            raise LLMProviderError(f"OpenRouter error: {e}")

    def is_available(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ OpenRouter API.

        Returns:
            True –µ—Å–ª–∏ API –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –∫–ª—é—á –≤–∞–ª–∏–¥–µ–Ω
        """
        try:
            # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
            with httpx.Client(timeout=5) as client:
                response = client.get(
                    f"{self.base_url}/models",
                    headers={"Authorization": f"Bearer {self.api_key}"}
                )
                return response.status_code == 200
        except:
            return False

    async def list_models(self) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

        Returns:
            –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        try:
            response = await self.client.get(f"{self.base_url}/models")
            response.raise_for_status()
            data = response.json()

            return data.get("data", [])
        except Exception as e:
            raise LLMProviderError(f"Cannot list models: {e}")

    async def get_model_info(self, model: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏.

        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        """
        models = await self.list_models()

        for m in models:
            if m.get("id") == model:
                return m

        raise LLMProviderError(f"Model {model} not found")

    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç HTTP –∫–ª–∏–µ–Ω—Ç"""
        await self.client.aclose()


# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Message –∫–ª–∞—Å—Å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π reasoning
class ReasoningMessage(Message):
    """–°–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π reasoning_details"""

    def __init__(self, role: str, content: str, reasoning_details: Optional[Dict] = None):
        super().__init__(role, content)
        self.reasoning_details = reasoning_details

    def to_dict(self) -> Dict[str, Any]:
        result = super().to_dict()
        if self.reasoning_details:
            result["reasoning_details"] = self.reasoning_details
        return result


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è
async def create_openrouter_provider(
        model: str = "openai/gpt-oss-20b:free",
        api_key: Optional[str] = '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',
        enable_reasoning: bool = False,
        **kwargs
) -> OpenRouterProvider:
    """
    –°–æ–∑–¥–∞—ë—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç OpenRouter –ø—Ä–æ–≤–∞–π–¥–µ—Ä.

    Args:
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        api_key: API –∫–ª—é—á
        enable_reasoning: –í–∫–ª—é—á–∏—Ç—å reasoning
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π OpenRouterProvider
    """
    return OpenRouterProvider(
        model=model,
        api_key=api_key,
        enable_reasoning=enable_reasoning,
        **kwargs
    )


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import asyncio


    async def test_openrouter():
        """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

        print("=" * 80)
        print("OPENROUTER PROVIDER TEST")
        print("=" * 80)

        # API –∫–ª—é—á (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π!)
        API_KEY = "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"

        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        print("\nüìç Creating provider...")
        try:
            provider = create_openrouter_provider(
                model="openai/gpt-oss-20b:free",
                api_key=API_KEY,
                temperature=0.7,
                enable_reasoning=True
            )
            print(f"‚úÖ Provider ready: {provider}")
        except LLMProviderError as e:
            print(f"‚ùå Error: {e}")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        if provider.is_available():
            print("‚úÖ API is available")
        else:
            print("‚ö†Ô∏è  API check failed")

        # –¢–µ—Å—Ç 1: –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
        print("\n" + "‚îÄ" * 80)
        print("TEST 1: Simple question")
        print("‚îÄ" * 80)

        response = await provider.generate_simple(
            user_message="What is 2+2? Answer in one sentence.",
            system_prompt="You are a helpful AI assistant."
        )

        print(f"\nü§ñ Response: {response.content}")

        # –¢–µ—Å—Ç 2: Reasoning (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
        print("\n" + "‚îÄ" * 80)
        print("TEST 2: Reasoning test")
        print("‚îÄ" * 80)

        response = await provider.generate_simple(
            user_message="How many r's are in the word 'strawberry'?"
        )

        print(f"\nü§ñ Response: {response.content}")

        if hasattr(response, 'reasoning_details') and response.reasoning_details:
            print(f"\nüß† Reasoning details: {response.reasoning_details}")

        # –¢–µ—Å—Ç 3: –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ reasoning
        print("\n" + "‚îÄ" * 80)
        print("TEST 3: Continue reasoning")
        print("‚îÄ" * 80)

        # –°–æ–∑–¥–∞—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å reasoning_details
        messages = [
            Message(role="user", content="How many r's are in the word 'strawberry'?"),
            ReasoningMessage(
                role="assistant",
                content=response.content,
                reasoning_details=getattr(response, 'reasoning_details', None)
            ),
            Message(role="user", content="Are you sure? Think carefully.")
        ]

        response2 = await provider.generate(messages, preserve_reasoning=True)
        print(f"\nü§ñ Response: {response2.content}")

        # –¢–µ—Å—Ç 4: JSON –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        print("\n" + "‚îÄ" * 80)
        print("TEST 4: JSON generation")
        print("‚îÄ" * 80)

        response = await provider.generate_simple(
            user_message="""Generate a JSON object with these fields:
- name: random person name
- age: random age 20-50
- hobby: random hobby

Return ONLY JSON, no other text.""",
            system_prompt="You are a JSON generator. Return only valid JSON."
        )

        print(f"\nü§ñ Response:\n{response.content}")

        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
        try:
            content = response.content.strip()
            start = content.find('{')
            end = content.rfind('}') + 1

            if 0 <= start < end:
                json_str = content[start:end]
                data = json.loads(json_str)
                print(f"‚úÖ Valid JSON parsed: {data}")
            else:
                print("‚ö†Ô∏è  No JSON found in response")
        except json.JSONDecodeError as e:
            print(f"‚ùå Invalid JSON: {e}")

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º
        await provider.close()
        print("\n‚úÖ All tests completed!")


    asyncio.run(test_openrouter())
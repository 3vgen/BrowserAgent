"""
CLI - ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ AI Browser Agent
"""

import asyncio
import sys
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ src Ğ² path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.llm.ollama_provider import create_ollama_provider
from src.browser.manager import BrowserManager
from src.agents.orchestrator import Orchestrator


async def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ CLI"""

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                            â•‘
â•‘                    ğŸ¤– AI BROWSER AGENT v0.1                                â•‘
â•‘                                                                            â•‘
â•‘                    Powered by Ollama + Qwen 2.5                            â•‘
â•‘                                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
    MODEL = "qwen2.5:7b"
    MAX_STEPS = 20

    print(f"âš™ï¸  Configuration:")
    print(f"   Model: {MODEL}")
    print(f"   Max steps: {MAX_STEPS}")
    print()

    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    print("ğŸš€ Starting up...\n")

    try:
        # LLM
        print("ğŸ“ Setting up LLM provider...")
        llm = await create_ollama_provider(model=MODEL)
        print("âœ… LLM ready")

        # Browser
        print("ğŸ“ Starting browser...")
        browser = BrowserManager(
            headless=False,
            slow_mo=300,
            profile_dir="./data/browser_profile"
        )
        await browser.start()
        print("âœ… Browser ready")

        # Agent (now using Orchestrator with sub-agents)
        print("ğŸ“ Creating orchestrator with sub-agents...")
        orchestrator = Orchestrator(
            llm_provider=llm,
            browser=browser,
            max_steps=MAX_STEPS,
            verbose=True
        )
        print("âœ… Orchestrator ready")
        print("   ğŸ‘ï¸  Vision Agent - analyzes pages")
        print("   ğŸ¤– Action Agent - decides actions\n")

    except Exception as e:
        print(f"\nâŒ Startup failed: {e}")
        print("\nMake sure Ollama is running:")
        print("  ollama serve")
        return

    # Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ»
    print("=" * 80)
    print("ğŸ¯ READY! Enter your tasks below.")
    print("=" * 80)
    print("\nğŸ’¡ Examples:")
    print("   â€¢ Search for 'AI news' on Google")
    print("   â€¢ Go to Wikipedia and find article about Python")
    print("   â€¢ Open Hacker News and find top story")
    print("\nğŸ’¬ Commands:")
    print("   â€¢ Type your task and press Enter")
    print("   â€¢ 'exit' or 'quit' to stop")
    print("   â€¢ 'url <address>' to navigate somewhere first")
    print()

    try:
        while True:
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            print("â”€" * 80)
            user_input = input("ğŸ¯ Your task: ").strip()

            if not user_input:
                continue

            # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°
            if user_input.lower() in ['exit', 'quit', 'q']:
                print("\nğŸ‘‹ Goodbye!")
                break

            # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸
            if user_input.lower().startswith('url '):
                url = user_input[4:].strip()
                print(f"\nğŸŒ Navigating to {url}...")
                result = await browser.navigate(url)
                if result['success']:
                    print(f"âœ… Loaded: {result['title']}")
                else:
                    print(f"âŒ Failed: {result.get('error')}")
                continue

            # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€
            result = await orchestrator.execute_task(
                goal=user_input,
                start_url=None  # ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
            )

            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            print("\n" + "=" * 80)
            if result['success']:
                print(f"âœ… SUCCESS")
                print(f"ğŸ“‹ Result: {result.get('result')}")
            else:
                print(f"âŒ FAILED")
                print(f"âš ï¸  Error: {result.get('error')}")
            print(f"ğŸ“Š Steps completed: {result.get('steps_completed')}")
            print("=" * 80 + "\n")

    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  Interrupted by user")

    finally:
        # Cleanup
        print("\nğŸ”’ Shutting down...")
        await browser.close()
        await llm.close()
        print("âœ… Cleanup complete")


if __name__ == "__main__":
    asyncio.run(main())

    # url https://www.google.com
    # go to wikipedia and find artical about 'ĞšĞ¾Ñ€Ğ¾Ğ»ÑŒ Ğ¸ Ğ¨ÑƒÑ‚'
